#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì–‘ì ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ BTC íŠ¸ë ˆì´ë”© ë´‡ - Ubuntu ë²„ì „
15ë¶„ë´‰ & 4ì‹œê°„ë´‰ ë©€í‹°íƒ€ì„í”„ë ˆì„ ë¶„ì„ + ë ˆë²„ë¦¬ì§€ ì„¤ì •
"""

import os
import time
import pandas as pd
import numpy as np
from datetime import datetime
import pytz
import ccxt
import warnings
import traceback
import argparse
import pickle
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import random
import string
import sys
import logging
from collections import deque
import platform
import hashlib

# === ë¦¬ëˆ…ìŠ¤ í˜¸í™˜ì„± ì„¤ì • ===
IS_LINUX = platform.system() == "Linux"
IS_WINDOWS = platform.system() == "Windows"

# ë””ë ‰í† ë¦¬ ìƒì„±
BASE_DIR = Path(os.path.expanduser("~")) / "quantum_trading"
DATA_DIR = BASE_DIR / "data"
MODEL_DIR = BASE_DIR / "models"
LOG_DIR = BASE_DIR / "logs"

for directory in [BASE_DIR, DATA_DIR, MODEL_DIR, LOG_DIR]:
    directory.mkdir(parents=True, exist_ok=True)

# íŒŒì¼ ê²½ë¡œ ì •ì˜
MARKET_DATA_FILE_15M = DATA_DIR / "market_data_15m.csv"
MARKET_DATA_FILE_4H = DATA_DIR / "market_data_4h.csv"
TRADE_HISTORY_FILE = DATA_DIR / "trade_history.pkl"
MODEL_FILE_15M = MODEL_DIR / "quantum_model_15m.pkl"
MODEL_FILE_4H = MODEL_DIR / "quantum_model_4h.pkl"
PERFORMANCE_LOG_FILE = DATA_DIR / "performance_log.csv"
TRAILING_STOP_FILE = DATA_DIR / "trailing_stops.pkl"
PATTERN_LEARNING_FILE = DATA_DIR / "pattern_learning.pkl"


# ë¦¬ëˆ…ìŠ¤ í˜¸í™˜ ë¡œê¹… í¬ë§·
class LinuxCompatibleFormatter(logging.Formatter):
    def format(self, record):
        # ë¦¬ëˆ…ìŠ¤ì—ì„œëŠ” ì´ëª¨ì§€ ì œê±°
        if IS_LINUX:
            record.msg = self._replace_emojis(record.msg)
        return super().format(record)

    def _replace_emojis(self, text):
        if not isinstance(text, str):
            return text

        replacements = {
            'ğŸš€': '[LAUNCH]', 'ğŸ“ˆ': '[UP]', 'âœ…': '[OK]', 'âŒ': '[ERROR]',
            'âš ï¸': '[WARN]', 'ğŸ”®': '[QUANTUM]', 'ğŸ¯': '[TARGET]', 'ğŸ“Š': '[CHART]',
            'ğŸ“¡': '[RADAR]', 'â°': '[CLOCK]', 'ğŸ”„': '[SYNC]', 'ğŸ”’': '[LOCK]',
            'ğŸ“¦': '[PACKAGE]', 'ğŸ†•': '[NEW]', 'â¸ï¸': '[PAUSE]', 'ğŸ²': '[DICE]',
            'ğŸ’¾': '[SAVE]', 'ğŸ“': '[FOLDER]', 'ğŸ›‘': '[STOP]', 'ğŸ”¥': '[FIRE]',
            'ğŸ¤–': '[ROBOT]', 'ğŸ–¥ï¸': '[PC]', 'ğŸ”§': '[TOOL]', 'ğŸ’¡': '[IDEA]',
            'ğŸ“š': '[BOOKS]', 'âš¡': '[ZAP]', 'ğŸ¨': '[ART]', 'ğŸ”': '[SEARCH]',
            'ğŸ’°': '[MONEY]', 'ğŸ“‰': '[DOWN]', 'ğŸª': '[CIRCUS]', 'ğŸ†': '[TROPHY]',
            'ğŸ””': '[BELL]', 'ğŸ“': '[NOTE]', 'ğŸ“Œ': '[PIN]', 'ğŸ“': '[LOCATION]',
            'ğŸ•’': '[TIME]', 'ğŸŒŸ': '[STAR]', 'â­': '[STAR]', 'ğŸŒ™': '[MOON]',
            'â˜€ï¸': '[SUN]', 'ğŸ‰': '[PARTY]', 'ğŸ”‘': '[KEY]', 'ğŸšª': '[DOOR]',
            'ğŸ¢': '[ROLLER]', 'ğŸ”„': '[TRAILING]', 'ğŸ“‰': '[FALL]',
            'ğŸ§ ': '[BRAIN]', 'ğŸ“š': '[LEARN]', 'ğŸ¯': '[BONUS]', 'ğŸ“Š': '[ANALYSIS]',
            'âš–ï¸': '[LEVERAGE]'
        }

        for emoji, replacement in replacements.items():
            text = text.replace(emoji, replacement)
        return text


# ë¡œê¹… ì„¤ì •
LOG_FILE = LOG_DIR / "quantum_trading_bot.log"
log_formatter = LinuxCompatibleFormatter('%(asctime)s - %(levelname)s - %(message)s')

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

for handler in logging.getLogger().handlers:
    handler.setFormatter(log_formatter)

logger = logging.getLogger(__name__)
warnings.filterwarnings("ignore")

# === OKX ì‹¤ê±°ë˜ API ì¸ì¦ ===
API_KEY = os.getenv("OKXYH_API_KEY")
API_SECRET = os.getenv("OKXYH_API_SECRET")
API_PASSPHRASE = os.getenv("OKXYH_API_PASSPHRASE")

# API í‚¤ê°€ ì—†ëŠ” ê²½ìš° í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ ì‹œë„
if not API_KEY:
    API_KEY = os.getenv("OKX_API_KEY")
if not API_SECRET:
    API_SECRET = os.getenv("OKX_API_SECRET")
if not API_PASSPHRASE:
    API_PASSPHRASE = os.getenv("OKX_API_PASSPHRASE")

# í™˜ê²½ë³€ìˆ˜ì—ë„ ì—†ëŠ” ê²½ìš° ìƒŒë“œë°•ìŠ¤ ëª¨ë“œ
if not API_KEY or not API_SECRET or not API_PASSPHRASE:
    logger.warning("[WARN] í™˜ê²½ë³€ìˆ˜ì—ì„œ API ì¸ì¦ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    logger.info("[INFO] .env íŒŒì¼ì„ ìƒì„±í•˜ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    USE_SANDBOX = True
else:
    USE_SANDBOX = False

# OKX ê±°ë˜ì†Œ ì„¤ì •
exchange_config = {
    'apiKey': API_KEY,
    'secret': API_SECRET,
    'password': API_PASSPHRASE,
    'sandbox': USE_SANDBOX,
    'enableRateLimit': True,
}

exchange = ccxt.okx(exchange_config)

# === ê±°ë˜ ì„¤ì • ===
SYMBOL = "BTC/USDT:USDT"  # OKX ì„ ë¬¼ ì‹¬ë³¼
TIMEFRAME_15M = "15m"  # 15ë¶„ë´‰
TIMEFRAME_4H = "4h"  # 4ì‹œê°„ë´‰
CANDLE_LIMIT = 200
CONTRACT_AMOUNT = 0.1
INTERVAL_NORMAL = 900  # 15ë¶„ (15ë¶„ë´‰ ì£¼ê¸°ì— ë§ì¶¤)
INTERVAL_ACTIVE = 300  # 5ë¶„ (í™œì„± ê±°ë˜ ì‹œ)
INTERVAL_WAITING = 600  # 10ë¶„ (ëŒ€ê¸° ëª¨ë“œ)
TRADING_MODE = "cross"

# ë ˆë²„ë¦¬ì§€ ì„¤ì • (ê¸°ë³¸ê°’ 100x, ëª…ë ¹ì¤„ì—ì„œ ì¡°ì • ê°€ëŠ¥)
LEVERAGE = 100

# ì†ìµ ê´€ë¦¬ ì„¤ì • (ë ˆë²„ë¦¬ì§€ ë°˜ì˜)
TAKE_PROFIT_PERCENT = 5000.0 / LEVERAGE  # ë ˆë²„ë¦¬ì§€ ë°˜ì˜
STOP_LOSS_PERCENT = -5000.0 / LEVERAGE  # ë ˆë²„ë¦¬ì§€ ë°˜ì˜
TRAILING_STOP_PERCENT = 5.0  # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ 5%
EMERGENCY_LIQUIDATION_THRESHOLD = -10.0
QUANTUM_FEATURE_DIMENSION = 5  # íŠ¹ì§• ê°œìˆ˜ 5ê°œë¡œ ìˆ˜ì • (íŒ¨í„´ íŠ¹ì§• í¬í•¨)
SIGNAL_MATCH_THRESHOLD = 0.7  # 70% ì´ìƒ ì¼ì¹˜ ì‹œ ë§¤ìˆ˜

# === ê°•í™”í•™ìŠµ ë° íŒ¨í„´ í•™ìŠµ ì„¤ì • ===
REINFORCEMENT_WEIGHT = 1.5  # ìˆ˜ìµì„± íŒ¨í„´ ê°€ì¤‘ì¹˜
MIN_PATTERN_OCCURRENCE = 3  # ìµœì†Œ íŒ¨í„´ ë°œìƒ íšŸìˆ˜
PATTERN_SIMILARITY_THRESHOLD = 0.8  # íŒ¨í„´ ìœ ì‚¬ë„ ì„ê³„ê°’

# ì„±ê³¼ ë°ì´í„° êµ¬ì¡°
PERFORMANCE_DATA = {
    'total_trades': 0,
    'total_pnl': 0.0,
    'winning_trades': 0,
    'initial_balance': 0.0,
    'recent_trades': deque(maxlen=100),
    'signal_accuracy_history': deque(maxlen=50),
    'similar_trade_patterns': {},
    'market_regime_performance': {},
    'time_based_performance': {}
}

# íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ë°ì´í„° êµ¬ì¡°
TRAILING_STOPS = {}

# íŒ¨í„´ í•™ìŠµ ë°ì´í„° êµ¬ì¡°
PATTERN_LEARNING_DATA = {
    'profitable_patterns': {},
    'unprofitable_patterns': {},
    'pattern_weights': {},
    'learning_history': [],
    'last_retrain': None
}
#-------
def load_okx_trade_history():
    """OKX ê±°ë˜ ë‚´ì—­ì„ ë¡œë“œí•˜ì—¬ í•™ìŠµ ë°ì´í„°ì— í†µí•©"""
    try:
        history_file = DATA_DIR / "okx_trade_history.pkl"
        if history_file.exists():
            with open(history_file, 'rb') as f:
                okx_trades = pickle.load(f)

            logger.info(f"[LEARN] OKX ê±°ë˜ ë‚´ì—­ ë¡œë“œ: {len(okx_trades)}ê°œ ê±°ë˜")

            # ê¸°ì¡´ í•™ìŠµ ë°ì´í„°ì™€ í†µí•©
            for trade in okx_trades:
                # íŒ¨í„´ í•™ìŠµ ë°ì´í„° ì—…ë°ì´íŠ¸
                update_pattern_learning(trade)

            logger.info("[LEARN] OKX ê±°ë˜ ë‚´ì—­ í•™ìŠµ ë°ì´í„° í†µí•© ì™„ë£Œ")
            return True
        else:
            logger.info("[LEARN] OKX ê±°ë˜ ë‚´ì—­ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return False
    except Exception as e:
        logger.error(f"[ERROR] OKX ê±°ë˜ ë‚´ì—­ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False


# ë©”ì¸ í•¨ìˆ˜ ìˆ˜ì • (main() í•¨ìˆ˜ ë‚´ì— ì¶”ê°€)
def main():
    # ... ê¸°ì¡´ ì½”ë“œ ...

    # OKX ê±°ë˜ ë‚´ì—­ ë¡œë“œ ë° í•™ìŠµ
    load_okx_trade_history()

    # ... ë‚˜ë¨¸ì§€ ì½”ë“œ ...
#-------
# === íŒ¨í„´ í•™ìŠµ ê´€ë¦¬ í•¨ìˆ˜ ===
def load_pattern_learning():
    """íŒ¨í„´ í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
    global PATTERN_LEARNING_DATA
    try:
        if PATTERN_LEARNING_FILE.exists():
            with open(PATTERN_LEARNING_FILE, 'rb') as f:
                PATTERN_LEARNING_DATA = pickle.load(f)
            logger.info("[LEARN] íŒ¨í„´ í•™ìŠµ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            logger.info(f"[LEARN] ìˆ˜ìµì„± íŒ¨í„´: {len(PATTERN_LEARNING_DATA['profitable_patterns'])}ê°œ")
            logger.info(f"[LEARN] ë¹„ìˆ˜ìµì„± íŒ¨í„´: {len(PATTERN_LEARNING_DATA['unprofitable_patterns'])}ê°œ")
            logger.info(f"[LEARN] íŒ¨í„´ ê°€ì¤‘ì¹˜: {len(PATTERN_LEARNING_DATA['pattern_weights'])}ê°œ")
    except Exception as e:
        logger.error(f"[ERROR] íŒ¨í„´ í•™ìŠµ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        PATTERN_LEARNING_DATA = {
            'profitable_patterns': {},
            'unprofitable_patterns': {},
            'pattern_weights': {},
            'learning_history': [],
            'last_retrain': None
        }


def save_pattern_learning():
    """íŒ¨í„´ í•™ìŠµ ë°ì´í„° ì €ì¥"""
    try:
        with open(PATTERN_LEARNING_FILE, 'wb') as f:
            pickle.dump(PATTERN_LEARNING_DATA, f)
        logger.debug("[LEARN] íŒ¨í„´ í•™ìŠµ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"[ERROR] íŒ¨í„´ í•™ìŠµ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")


def generate_pattern_hash(pattern):
    """íŒ¨í„´ í•´ì‹œ ìƒì„±"""
    pattern_str = ''.join(map(str, pattern))
    return hashlib.md5(pattern_str.encode()).hexdigest()[:12]


def calculate_pattern_similarity(pattern1, pattern2):
    """ë‘ íŒ¨í„´ ê°„ ìœ ì‚¬ë„ ê³„ì‚°"""
    if len(pattern1) != len(pattern2):
        return 0

    matches = sum(1 for p1, p2 in zip(pattern1, pattern2) if p1 == p2)
    return matches / len(pattern1)


def find_similar_pattern(current_pattern, pattern_dict, threshold=PATTERN_SIMILARITY_THRESHOLD):
    """ìœ ì‚¬í•œ íŒ¨í„´ ì°¾ê¸°"""
    if not current_pattern:
        return None, 0

    best_similarity = 0
    best_pattern = None
    best_pattern_id = None

    for pattern_id, pattern_data in pattern_dict.items():
        similarity = calculate_pattern_similarity(current_pattern, pattern_data['pattern'])
        if similarity > best_similarity and similarity >= threshold:
            best_similarity = similarity
            best_pattern = pattern_data
            best_pattern_id = pattern_id

    return best_pattern_id, best_similarity


def update_pattern_learning(trade_record):
    """íŒ¨í„´ í•™ìŠµ ì—…ë°ì´íŠ¸"""
    try:
        pattern = trade_record.get('trade_pattern')
        pnl_usdt = trade_record.get('pnl_usdt', 0)
        pnl_percent = trade_record.get('pnl_percent', 0)

        if not pattern:
            return

        pattern_hash = generate_pattern_hash(pattern)

        # íŒ¨í„´ ë°ì´í„° ì¤€ë¹„
        pattern_data = {
            'pattern': pattern,
            'pnl_usdt': pnl_usdt,
            'pnl_percent': pnl_percent,
            'count': 1,
            'total_pnl': pnl_usdt,
            'avg_pnl': pnl_usdt,
            'last_seen': datetime.now().isoformat(),
            'market_regime': trade_record.get('market_regime', 'UNKNOWN'),
            'hour_of_day': trade_record.get('hour_of_day', 0)
        }

        # ìˆ˜ìµì„± ê¸°ì¤€ (0.1% ì´ìƒ ìˆ˜ìµ)
        is_profitable = pnl_percent > 0.1

        if is_profitable:
            # ìˆ˜ìµì„± íŒ¨í„´ ì—…ë°ì´íŠ¸
            if pattern_hash in PATTERN_LEARNING_DATA['profitable_patterns']:
                existing = PATTERN_LEARNING_DATA['profitable_patterns'][pattern_hash]
                existing['count'] += 1
                existing['total_pnl'] += pnl_usdt
                existing['avg_pnl'] = existing['total_pnl'] / existing['count']
                existing['last_seen'] = datetime.now().isoformat()
                logger.info(
                    f"[LEARN] ê¸°ì¡´ ìˆ˜ìµì„± íŒ¨í„´ ì—…ë°ì´íŠ¸: {pattern_hash} (íšŸìˆ˜: {existing['count']}, í‰ê·  PnL: {existing['avg_pnl']:.3f} USDT)")
            else:
                PATTERN_LEARNING_DATA['profitable_patterns'][pattern_hash] = pattern_data
                logger.info(f"[LEARN] ìƒˆë¡œìš´ ìˆ˜ìµì„± íŒ¨í„´ ë“±ë¡: {pattern_hash} (PnL: {pnl_usdt:.3f} USDT)")

            # íŒ¨í„´ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ (ìˆ˜ìµì„± íŒ¨í„´ì€ ê°€ì¤‘ì¹˜ ì¦ê°€)
            current_weight = PATTERN_LEARNING_DATA['pattern_weights'].get(pattern_hash, 1.0)
            new_weight = min(current_weight * REINFORCEMENT_WEIGHT, 5.0)  # ìµœëŒ€ 5ë°°ê¹Œì§€
            PATTERN_LEARNING_DATA['pattern_weights'][pattern_hash] = new_weight

            logger.info(f"[LEARN] ìˆ˜ìµì„± íŒ¨í„´ ê°€ì¤‘ì¹˜ ì¦ê°€: {pattern_hash} ({current_weight:.2f}x â†’ {new_weight:.2f}x)")

        else:
            # ë¹„ìˆ˜ìµì„± íŒ¨í„´ ì—…ë°ì´íŠ¸
            if pattern_hash in PATTERN_LEARNING_DATA['unprofitable_patterns']:
                existing = PATTERN_LEARNING_DATA['unprofitable_patterns'][pattern_hash]
                existing['count'] += 1
                existing['total_pnl'] += pnl_usdt
                existing['avg_pnl'] = existing['total_pnl'] / existing['count']
                existing['last_seen'] = datetime.now().isoformat()
                logger.info(
                    f"[LEARN] ê¸°ì¡´ ë¹„ìˆ˜ìµì„± íŒ¨í„´ ì—…ë°ì´íŠ¸: {pattern_hash} (íšŸìˆ˜: {existing['count']}, í‰ê·  PnL: {existing['avg_pnl']:.3f} USDT)")
            else:
                PATTERN_LEARNING_DATA['unprofitable_patterns'][pattern_hash] = pattern_data
                logger.info(f"[LEARN] ìƒˆë¡œìš´ ë¹„ìˆ˜ìµì„± íŒ¨í„´ ë“±ë¡: {pattern_hash} (PnL: {pnl_usdt:.3f} USDT)")

            # íŒ¨í„´ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ (ë¹„ìˆ˜ìµì„± íŒ¨í„´ì€ ê°€ì¤‘ì¹˜ ê°ì†Œ)
            current_weight = PATTERN_LEARNING_DATA['pattern_weights'].get(pattern_hash, 1.0)
            new_weight = max(current_weight / REINFORCEMENT_WEIGHT, 0.2)  # ìµœì†Œ 0.2ë°°ê¹Œì§€
            PATTERN_LEARNING_DATA['pattern_weights'][pattern_hash] = new_weight

            logger.info(f"[LEARN] ë¹„ìˆ˜ìµì„± íŒ¨í„´ ê°€ì¤‘ì¹˜ ê°ì†Œ: {pattern_hash} ({current_weight:.2f}x â†’ {new_weight:.2f}x)")

        # í•™ìŠµ ê¸°ë¡ ì €ì¥
        learning_record = {
            'timestamp': datetime.now().isoformat(),
            'pattern_hash': pattern_hash,
            'pattern': pattern,
            'pnl_usdt': pnl_usdt,
            'pnl_percent': pnl_percent,
            'is_profitable': is_profitable,
            'new_weight': PATTERN_LEARNING_DATA['pattern_weights'].get(pattern_hash, 1.0)
        }
        PATTERN_LEARNING_DATA['learning_history'].append(learning_record)

        # ìµœê·¼ 1000ê°œ ê¸°ë¡ë§Œ ìœ ì§€
        if len(PATTERN_LEARNING_DATA['learning_history']) > 1000:
            PATTERN_LEARNING_DATA['learning_history'] = PATTERN_LEARNING_DATA['learning_history'][-1000:]

        save_pattern_learning()

    except Exception as e:
        logger.error(f"[ERROR] íŒ¨í„´ í•™ìŠµ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")


def get_pattern_bonus(current_pattern, market_regime, hour_of_day):
    """íŒ¨í„´ ë³´ë„ˆìŠ¤ ì ìˆ˜ ê³„ì‚°"""
    if not current_pattern:
        return 0

    bonus_score = 0
    pattern_hash = generate_pattern_hash(current_pattern)

    # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” íŒ¨í„´ ê²€ìƒ‰
    if pattern_hash in PATTERN_LEARNING_DATA['profitable_patterns']:
        pattern_data = PATTERN_LEARNING_DATA['profitable_patterns'][pattern_hash]
        weight = PATTERN_LEARNING_DATA['pattern_weights'].get(pattern_hash, 1.0)

        if pattern_data['count'] >= MIN_PATTERN_OCCURRENCE:
            # ê¸°ë³¸ ë³´ë„ˆìŠ¤ + ê°€ì¤‘ì¹˜ ì ìš©
            base_bonus = min(pattern_data['avg_pnl'] * 10, 0.5)  # ìµœëŒ€ 0.5ì 
            regime_bonus = 0.1 if pattern_data['market_regime'] == market_regime else 0
            time_bonus = 0.05 if pattern_data['hour_of_day'] == hour_of_day else 0

            bonus_score = (base_bonus + regime_bonus + time_bonus) * weight
            logger.info(
                f"[BONUS] ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­: {pattern_hash} (ë³´ë„ˆìŠ¤: {bonus_score:.3f}, ê°€ì¤‘ì¹˜: {weight:.2f}x, íšŸìˆ˜: {pattern_data['count']})")

    # ìœ ì‚¬ íŒ¨í„´ ê²€ìƒ‰ (ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°)
    else:
        similar_pattern_id, similarity = find_similar_pattern(
            current_pattern,
            PATTERN_LEARNING_DATA['profitable_patterns']
        )

        if similar_pattern_id and similarity >= 0.7:  # 70% ì´ìƒ ìœ ì‚¬
            pattern_data = PATTERN_LEARNING_DATA['profitable_patterns'][similar_pattern_id]
            weight = PATTERN_LEARNING_DATA['pattern_weights'].get(similar_pattern_id, 1.0)

            if pattern_data['count'] >= MIN_PATTERN_OCCURRENCE:
                # ìœ ì‚¬ë„ì— ë”°ë¥¸ ë³´ë„ˆìŠ¤
                base_bonus = min(pattern_data['avg_pnl'] * 10, 0.3) * similarity
                regime_bonus = 0.1 if pattern_data['market_regime'] == market_regime else 0
                time_bonus = 0.05 if pattern_data['hour_of_day'] == hour_of_day else 0

                bonus_score = (base_bonus + regime_bonus + time_bonus) * weight
                logger.info(
                    f"[BONUS] ìœ ì‚¬ íŒ¨í„´ ë§¤ì¹­: {similar_pattern_id} (ìœ ì‚¬ë„: {similarity:.1%}, ë³´ë„ˆìŠ¤: {bonus_score:.3f}, íšŸìˆ˜: {pattern_data['count']})")

    return min(bonus_score, 1.0)  # ìµœëŒ€ 1.0ì  ì œí•œ


def retrain_models_with_patterns():
    """íŒ¨í„´ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ"""
    try:
        logger.info("[LEARN] íŒ¨í„´ í•™ìŠµ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ ì‹œì‘...")

        # ìµœê·¼ ì¬í•™ìŠµ ì‹œê°„ í™•ì¸ (24ì‹œê°„ë§ˆë‹¤ ì¬í•™ìŠµ)
        current_time = datetime.now()
        last_retrain = PATTERN_LEARNING_DATA.get('last_retrain')
        if last_retrain:
            last_retrain_time = datetime.fromisoformat(last_retrain)
            hours_since_retrain = (current_time - last_retrain_time).total_seconds() / 3600
            if hours_since_retrain < 24:
                logger.info(f"[LEARN] ìµœê·¼ ì¬í•™ìŠµ ì´í›„ {hours_since_retrain:.1f}ì‹œê°„ ê²½ê³¼, ì¬í•™ìŠµ ìŠ¤í‚µ")
                return

        # ë°ì´í„° ìˆ˜ì§‘
        df_15m = fetch_ohlcv(timeframe=TIMEFRAME_15M, limit=1000)
        df_4h = fetch_ohlcv(timeframe=TIMEFRAME_4H, limit=1000)

        if df_15m is None or df_4h is None:
            logger.warning("[LEARN] ì¬í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ë¶€ì¡±")
            return

        # 15ë¶„ë´‰ ëª¨ë¸ ì¬í•™ìŠµ
        quantum_model_15m = QuantumTradingModel(timeframe="15m")
        quantum_model_15m.train(df_15m, force_retrain=True)

        # 4ì‹œê°„ë´‰ ëª¨ë¸ ì¬í•™ìŠµ
        quantum_model_4h = QuantumTradingModel(timeframe="4h")
        quantum_model_4h.train(df_4h, force_retrain=True)

        PATTERN_LEARNING_DATA['last_retrain'] = current_time.isoformat()
        save_pattern_learning()

        logger.info("[LEARN] ëª¨ë¸ ì¬í•™ìŠµ ì™„ë£Œ")

    except Exception as e:
        logger.error(f"[ERROR] ëª¨ë¸ ì¬í•™ìŠµ ì‹¤íŒ¨: {e}")


def analyze_pattern_performance():
    """íŒ¨í„´ ì„±ê³¼ ë¶„ì„"""
    try:
        profitable_count = len(PATTERN_LEARNING_DATA['profitable_patterns'])
        unprofitable_count = len(PATTERN_LEARNING_DATA['unprofitable_patterns'])
        total_patterns = profitable_count + unprofitable_count

        if total_patterns == 0:
            logger.info("[ANALYSIS] ë¶„ì„í•  íŒ¨í„´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ìƒìœ„ ìˆ˜ìµì„± íŒ¨í„´ ì°¾ê¸°
        profitable_patterns = list(PATTERN_LEARNING_DATA['profitable_patterns'].values())
        profitable_patterns.sort(key=lambda x: x['avg_pnl'], reverse=True)

        logger.info("[ANALYSIS] === íŒ¨í„´ ì„±ê³¼ ë¶„ì„ ë¦¬í¬íŠ¸ ===")
        logger.info(f"[ANALYSIS] ì´ íŒ¨í„´: {total_patterns}ê°œ")
        logger.info(f"[ANALYSIS] ìˆ˜ìµì„± íŒ¨í„´: {profitable_count}ê°œ ({profitable_count / total_patterns:.1%})")
        logger.info(f"[ANALYSIS] ë¹„ìˆ˜ìµì„± íŒ¨í„´: {unprofitable_count}ê°œ ({unprofitable_count / total_patterns:.1%})")

        if profitable_patterns:
            top_patterns = profitable_patterns[:5]  # ìƒìœ„ 5ê°œ íŒ¨í„´
            logger.info("[ANALYSIS] --- ìƒìœ„ ìˆ˜ìµì„± íŒ¨í„´ ---")
            for i, pattern in enumerate(top_patterns, 1):
                pattern_hash = generate_pattern_hash(pattern['pattern'])
                weight = PATTERN_LEARNING_DATA['pattern_weights'].get(pattern_hash, 1.0)
                logger.info(
                    f"[ANALYSIS] Top {i}: í•´ì‹œ={pattern_hash}, í‰ê·  PnL={pattern['avg_pnl']:.3f} USDT, íšŸìˆ˜={pattern['count']}íšŒ, ê°€ì¤‘ì¹˜={weight:.2f}x")

        # íŒ¨í„´ ê°€ì¤‘ì¹˜ ë¶„í¬ ë¶„ì„
        weights = list(PATTERN_LEARNING_DATA['pattern_weights'].values())
        if weights:
            avg_weight = np.mean(weights)
            max_weight = np.max(weights)
            min_weight = np.min(weights)
            high_weight_count = len([w for w in weights if w > 2.0])  # 2.0x ì´ìƒ ê°€ì¤‘ì¹˜

            logger.info("[ANALYSIS] --- íŒ¨í„´ ê°€ì¤‘ì¹˜ ë¶„ì„ ---")
            logger.info(f"[ANALYSIS] í‰ê·  ê°€ì¤‘ì¹˜: {avg_weight:.2f}x")
            logger.info(f"[ANALYSIS] ìµœëŒ€ ê°€ì¤‘ì¹˜: {max_weight:.2f}x")
            logger.info(f"[ANALYSIS] ìµœì†Œ ê°€ì¤‘ì¹˜: {min_weight:.2f}x")
            logger.info(f"[ANALYSIS] ê³ ê°€ì¤‘ì¹˜ íŒ¨í„´(2.0xâ†‘): {high_weight_count}ê°œ")

        # ìµœê·¼ í•™ìŠµ í™œë™
        recent_learnings = PATTERN_LEARNING_DATA['learning_history'][-10:]  # ìµœê·¼ 10ê°œ í•™ìŠµ
        if recent_learnings:
            logger.info("[ANALYSIS] --- ìµœê·¼ í•™ìŠµ í™œë™ ---")
            for learning in recent_learnings[-5:]:  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ
                status = "ìˆ˜ìµ" if learning['is_profitable'] else "ì†ì‹¤"
                logger.info(
                    f"[ANALYSIS] {learning['timestamp'][11:19]} - {learning['pattern_hash']} - {status} - ê°€ì¤‘ì¹˜: {learning['new_weight']:.2f}x")

        logger.info("[ANALYSIS] === ë¶„ì„ ì™„ë£Œ ===")

    except Exception as e:
        logger.error(f"[ERROR] íŒ¨í„´ ì„±ê³¼ ë¶„ì„ ì‹¤íŒ¨: {e}")


# === íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ê´€ë¦¬ í•¨ìˆ˜ ===
def load_trailing_stops():
    """íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ë°ì´í„° ë¡œë“œ"""
    global TRAILING_STOPS
    try:
        if TRAILING_STOP_FILE.exists():
            with open(TRAILING_STOP_FILE, 'rb') as f:
                TRAILING_STOPS = pickle.load(f)
            logger.info("[TRAILING] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"[ERROR] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        TRAILING_STOPS = {}


def save_trailing_stops():
    """íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ë°ì´í„° ì €ì¥"""
    try:
        with open(TRAILING_STOP_FILE, 'wb') as f:
            pickle.dump(TRAILING_STOPS, f)
        logger.debug("[TRAILING] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"[ERROR] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")


def initialize_trailing_stop(position_id, entry_price, side, current_price):
    """íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì´ˆê¸°í™”"""
    try:
        if side == "long":
            trailing_stop_price = entry_price * (1 - TRAILING_STOP_PERCENT / 100)
            highest_price = current_price
        else:  # short
            trailing_stop_price = entry_price * (1 + TRAILING_STOP_PERCENT / 100)
            lowest_price = current_price

        TRAILING_STOPS[position_id] = {
            'position_id': position_id,
            'entry_price': entry_price,
            'side': side,
            'trailing_stop_price': trailing_stop_price,
            'highest_price': highest_price if side == "long" else None,
            'lowest_price': lowest_price if side == "short" else None,
            'activated': False,
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }

        logger.info(f"[TRAILING] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì´ˆê¸°í™”: {position_id}")
        logger.info(f"[TRAILING] ì§„ì…ê°€: {entry_price:.2f}, íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ê°€: {trailing_stop_price:.2f}")
        save_trailing_stops()

    except Exception as e:
        logger.error(f"[ERROR] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


def update_trailing_stop(position_id, current_price):
    """íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì—…ë°ì´íŠ¸"""
    try:
        if position_id not in TRAILING_STOPS:
            return False

        trailing_data = TRAILING_STOPS[position_id]
        side = trailing_data['side']

        if side == "long":
            # ìµœê³ ê°€ ì—…ë°ì´íŠ¸
            if current_price > trailing_data['highest_price']:
                trailing_data['highest_price'] = current_price
                # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ê°€ ì—…ë°ì´íŠ¸
                new_trailing_stop = current_price * (1 - TRAILING_STOP_PERCENT / 100)
                if new_trailing_stop > trailing_data['trailing_stop_price']:
                    trailing_data['trailing_stop_price'] = new_trailing_stop
                    trailing_data['activated'] = True
                    logger.info(f"[TRAILING] LONG íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì—…ë°ì´íŠ¸: {new_trailing_stop:.2f}")

            # ì²­ì‚° ì¡°ê±´ ì²´í¬
            if current_price <= trailing_data['trailing_stop_price']:
                logger.info(
                    f"[TRAILING] LONG íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì²­ì‚° ì¡°ê±´ ì¶©ì¡±: {current_price:.2f} <= {trailing_data['trailing_stop_price']:.2f}")
                return True

        else:  # short
            # ìµœì €ê°€ ì—…ë°ì´íŠ¸
            if current_price < trailing_data['lowest_price']:
                trailing_data['lowest_price'] = current_price
                # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ê°€ ì—…ë°ì´íŠ¸
                new_trailing_stop = current_price * (1 + TRAILING_STOP_PERCENT / 100)
                if new_trailing_stop < trailing_data['trailing_stop_price']:
                    trailing_data['trailing_stop_price'] = new_trailing_stop
                    trailing_data['activated'] = True
                    logger.info(f"[TRAILING] SHORT íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì—…ë°ì´íŠ¸: {new_trailing_stop:.2f}")

            # ì²­ì‚° ì¡°ê±´ ì²´í¬
            if current_price >= trailing_data['trailing_stop_price']:
                logger.info(
                    f"[TRAILING] SHORT íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì²­ì‚° ì¡°ê±´ ì¶©ì¡±: {current_price:.2f} >= {trailing_data['trailing_stop_price']:.2f}")
                return True

        trailing_data['updated_at'] = datetime.now().isoformat()
        return False

    except Exception as e:
        logger.error(f"[ERROR] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False


def remove_trailing_stop(position_id):
    """íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì œê±°"""
    try:
        if position_id in TRAILING_STOPS:
            del TRAILING_STOPS[position_id]
            save_trailing_stops()
            logger.info(f"[TRAILING] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì œê±°: {position_id}")
    except Exception as e:
        logger.error(f"[ERROR] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì œê±° ì‹¤íŒ¨: {e}")


def check_all_trailing_stops(current_price):
    """ëª¨ë“  íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì²´í¬"""
    try:
        positions_to_close = []
        for position_id, trailing_data in TRAILING_STOPS.items():
            if update_trailing_stop(position_id, current_price):
                positions_to_close.append(position_id)
        return positions_to_close
    except Exception as e:
        logger.error(f"[ERROR] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì²´í¬ ì‹¤íŒ¨: {e}")
        return []


# === ê¸°ìˆ ì  ì§€í‘œ í•¨ìˆ˜ ===
def calculate_rsi(prices, period=14):
    """RSI ê³„ì‚°"""
    try:
        delta = prices.diff()
        gain = delta.clip(lower=0)
        loss = -delta.clip(upper=0)
        avg_gain = gain.rolling(window=period).mean()
        avg_loss = loss.rolling(window=period).mean()
        rs = avg_gain / (avg_loss + 1e-9)
        rsi = 100 - (100 / (1 + rs))
        return rsi
    except Exception as e:
        logger.error(f"RSI ê³„ì‚° ì˜¤ë¥˜: {e}")
        return pd.Series([50] * len(prices), index=prices.index)


def calculate_macd(prices, fast=12, slow=26, signal=9):
    """MACD ê³„ì‚°"""
    try:
        exp1 = prices.ewm(span=fast).mean()
        exp2 = prices.ewm(span=slow).mean()
        macd = exp1 - exp2
        macd_signal = macd.ewm(span=signal).mean()
        macd_histogram = macd - macd_signal
        return macd, macd_signal, macd_histogram
    except Exception as e:
        logger.error(f"MACD ê³„ì‚° ì˜¤ë¥˜: {e}")
        empty_series = pd.Series([0] * len(prices), index=prices.index)
        return empty_series, empty_series, empty_series


def calculate_atr(high, low, close, period=14):
    """ATR ê³„ì‚°"""
    try:
        tr1 = high - low
        tr2 = abs(high - close.shift())
        tr3 = abs(low - close.shift())
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        atr = tr.rolling(period).mean()
        return atr
    except Exception as e:
        logger.error(f"ATR ê³„ì‚° ì˜¤ë¥˜: {e}")
        return pd.Series([0] * len(high), index=high.index)


def add_technical_indicators(df):
    """ë°ì´í„°í”„ë ˆì„ì— ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€"""
    df = df.copy()
    try:
        df['return'] = df['close'].pct_change()
        df['ma5'] = df['close'].rolling(5).mean()
        df['ma20'] = df['close'].rolling(20).mean()
        df['ma50'] = df['close'].rolling(50).mean()
        df['rsi'] = calculate_rsi(df['close'])

        macd, macd_signal, _ = calculate_macd(df['close'])
        df['macd'] = macd
        df['macd_signal'] = macd_signal

        df['atr'] = calculate_atr(df['high'], df['low'], df['close'])
        df['volatility'] = df['return'].rolling(20).std()
        df['volume_ma'] = df['volume'].rolling(20).mean()
        df['momentum'] = df['close'] / df['close'].shift(5) - 1
    except Exception as e:
        logger.error(f"ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
    return df


# === íŒŒì¼ ê´€ë¦¬ í•¨ìˆ˜ ===
def save_market_data(df, timeframe):
    """ì‹œì¥ ë°ì´í„° ì €ì¥"""
    try:
        if df is not None and len(df) > 0:
            file_path = MARKET_DATA_FILE_15M if timeframe == "15m" else MARKET_DATA_FILE_4H
            if file_path.exists():
                existing_data = pd.read_csv(file_path)
                combined_data = pd.concat([existing_data, df], ignore_index=True)
                combined_data = combined_data.drop_duplicates(subset=['ts'], keep='last')
            else:
                combined_data = df

            if len(combined_data) > 10000:
                combined_data = combined_data.tail(10000)

            combined_data.to_csv(file_path, index=False)
            logger.info(f"[FOLDER] {timeframe} ì‹œì¥ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {len(combined_data)}ê°œ ìº”ë“¤")
    except Exception as e:
        logger.error(f"ì‹œì¥ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")


def load_market_data(timeframe):
    """ì‹œì¥ ë°ì´í„° ë¡œë“œ"""
    try:
        file_path = MARKET_DATA_FILE_15M if timeframe == "15m" else MARKET_DATA_FILE_4H
        if file_path.exists():
            df = pd.read_csv(file_path)
            df['ts'] = pd.to_datetime(df['ts'], unit='ms')
            logger.info(f"[FOLDER] {timeframe} ì‹œì¥ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ìº”ë“¤")
            return df
        return None
    except Exception as e:
        logger.error(f"ì‹œì¥ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def load_trade_history():
    """ê±°ë˜ ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°"""
    try:
        if TRADE_HISTORY_FILE.exists():
            with open(TRADE_HISTORY_FILE, 'rb') as f:
                data = pickle.load(f)
                if 'recent_trades' in data and isinstance(data['recent_trades'], list):
                    data['recent_trades'] = deque(data['recent_trades'], maxlen=100)
                if 'signal_accuracy_history' in data and isinstance(data['signal_accuracy_history'], list):
                    data['signal_accuracy_history'] = deque(data['signal_accuracy_history'], maxlen=50)
                logger.info(f"[CHART] ê±°ë˜ ê¸°ë¡ ë¡œë“œ ì™„ë£Œ: {data['total_trades']}íšŒ ê±°ë˜")
                return data
    except Exception as e:
        logger.error(f"ê±°ë˜ ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
    return PERFORMANCE_DATA.copy()


def save_trade_history():
    """ê±°ë˜ ê¸°ë¡ ì €ì¥"""
    try:
        save_data = PERFORMANCE_DATA.copy()
        save_data['recent_trades'] = list(save_data['recent_trades'])
        save_data['signal_accuracy_history'] = list(save_data['signal_accuracy_history'])

        with open(TRADE_HISTORY_FILE, 'wb') as f:
            pickle.dump(save_data, f)
        logger.debug("ê±°ë˜ ê¸°ë¡ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ê±°ë˜ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")


def save_model(model, scaler, timeframe):
    """ëª¨ë¸ ì €ì¥"""
    try:
        model_data = {
            'model': model,
            'scaler': scaler,
            'saved_at': datetime.now().isoformat(),
            'timeframe': timeframe
        }
        model_file = MODEL_FILE_15M if timeframe == "15m" else MODEL_FILE_4H
        with open(model_file, 'wb') as f:
            pickle.dump(model_data, f)
        logger.info(f"[SAVE] {timeframe} ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")


def load_model(timeframe):
    """ëª¨ë¸ ë¡œë“œ"""
    try:
        model_file = MODEL_FILE_15M if timeframe == "15m" else MODEL_FILE_4H
        if model_file.exists():
            with open(model_file, 'rb') as f:
                model_data = pickle.load(f)
            logger.info(f"[SAVE] {timeframe} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            return model_data['model'], model_data['scaler']
        return None, None
    except Exception as e:
        logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None


def log_performance(metrics):
    """ì„±ê³¼ ì§€í‘œ ë¡œê¹…"""
    try:
        with open(PERFORMANCE_LOG_FILE, 'a', encoding='utf-8') as f:
            f.write(f"{datetime.now().isoformat()},{metrics}\n")
    except Exception as e:
        logger.error(f"ì„±ê³¼ ë¡œê¹… ì‹¤íŒ¨: {e}")


# === ë¨¸ì‹ ëŸ¬ë‹ ê´€ë ¨ í´ë˜ìŠ¤ ===
class SimpleScaler:
    """MinMaxScaler ëŒ€ì²´ êµ¬í˜„"""

    def __init__(self):
        self.min_ = None
        self.max_ = None
        self.data_min_ = None
        self.data_max_ = None

    def fit(self, X):
        if len(X) == 0:
            return self
        self.data_min_ = np.min(X, axis=0)
        self.data_max_ = np.max(X, axis=0)
        self.min_ = 0.0
        self.max_ = 1.0
        return self

    def transform(self, X):
        if self.data_min_ is None or self.data_max_ is None:
            return X
        X_std = (X - self.data_min_) / (self.data_max_ - self.data_min_ + 1e-9)
        X_scaled = X_std * (self.max_ - self.min_) + self.min_
        return X_scaled

    def fit_transform(self, X):
        self.fit(X)
        return self.transform(X)


class SimpleClassifier:
    """SVC ëŒ€ì²´ êµ¬í˜„"""

    def __init__(self):
        self.threshold = 0.5
        self.is_fitted = False
        self.weights = None

    def fit(self, X, y):
        if len(X) == 0 or len(y) == 0:
            self.is_fitted = False
            return self

        positive_samples = X[y == 1]
        negative_samples = X[y == 0]

        if len(positive_samples) > 0 and len(negative_samples) > 0:
            pos_mean = np.mean(positive_samples, axis=0)
            neg_mean = np.mean(negative_samples, axis=0)
            self.weights = pos_mean - neg_mean
            self.is_fitted = True
        else:
            self.is_fitted = False
        return self

    def predict(self, X):
        if not self.is_fitted:
            return np.random.randint(0, 2, len(X))
        scores = np.dot(X, self.weights)
        return (scores > 0).astype(int)

    def score(self, X, y):
        predictions = self.predict(X)
        return np.mean(predictions == y)


# scikit-learn ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
try:
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.svm import SVC

    SKLEARN_AVAILABLE = True
    logger.info("[OK] scikit-learn ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    SKLEARN_AVAILABLE = False
    MinMaxScaler = SimpleScaler
    SVC = SimpleClassifier
    logger.warning("[WARN] scikit-learn ì‚¬ìš© ë¶ˆê°€ - ë‹¨ìˆœ êµ¬í˜„ì²´ ì‚¬ìš©")


# === ì–‘ì ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ===
class QuantumTradingModel:
    def __init__(self, feature_dimension=QUANTUM_FEATURE_DIMENSION, timeframe="15m"):
        self.feature_dimension = feature_dimension
        self.timeframe = timeframe
        self.model = None
        self.scaler = MinMaxScaler()
        self.is_trained = False
        self.training_history = []
        self.pattern_aware = True  # íŒ¨í„´ ì¸ì‹ ê¸°ëŠ¥ í™œì„±í™”

    def prepare_quantum_features(self, df):
        """ì–‘ì ëª¨ë¸ìš© íŠ¹ì§• ì¶”ì¶œ (íŒ¨í„´ íŠ¹ì§• í¬í•¨)"""
        features = []
        df_with_indicators = add_technical_indicators(df)

        for i in range(len(df_with_indicators)):
            if i < 20:
                # íŠ¹ì§• ê°œìˆ˜ë¥¼ 5ê°œë¡œ ì¼ê´€ì„± ìˆê²Œ ìœ ì§€
                features.append([0.5, 0.5, 0.5, 0.5, 0.5])
                continue

            row = df_with_indicators.iloc[i]

            # RSI íŠ¹ì§•
            rsi_feature = min(max(row['rsi'] / 100.0, 0.0), 1.0) if not np.isnan(row['rsi']) else 0.5

            # ì´ë™í‰ê·  íŠ¹ì§•
            if not np.isnan(row['ma5']) and not np.isnan(row['ma20']) and row['ma20'] != 0:
                ma_diff = (row['ma5'] - row['ma20']) / row['ma20']
                ma_feature = min(max(ma_diff, -0.1), 0.1) * 5 + 0.5
            else:
                ma_feature = 0.5

            # ë³€ë™ì„± íŠ¹ì§•
            if not np.isnan(row['volatility']):
                vol_feature = min(max(row['volatility'] * 100, 0.0), 5.0) / 5.0
            else:
                vol_feature = 0.5

            # ATR íŠ¹ì§•
            if not np.isnan(row['atr']) and row['close'] != 0:
                atr_feature = min(max(row['atr'] / row['close'], 0.0), 0.1) * 10
            else:
                atr_feature = 0.5

            # íŒ¨í„´ íŠ¹ì§• (ìµœê·¼ 10ê°œ ë´‰ì˜ ìƒìŠ¹/í•˜ë½ íŒ¨í„´)
            pattern_feature = 0.5
            if self.pattern_aware and i >= 10:
                recent_closes = df_with_indicators['close'].iloc[i - 9:i + 1]
                pattern = []
                for j in range(1, len(recent_closes)):
                    if recent_closes.iloc[j] > recent_closes.iloc[j - 1]:
                        pattern.append(1)
                    elif recent_closes.iloc[j] < recent_closes.iloc[j - 1]:
                        pattern.append(-1)
                    else:
                        pattern.append(0)

                # íŒ¨í„´ ë³´ë„ˆìŠ¤ ì ìˆ˜ ê³„ì‚°
                current_hour = datetime.now().hour
                market_regime = detect_market_regime(df_with_indicators.iloc[:i + 1])
                pattern_bonus = get_pattern_bonus(pattern, market_regime, current_hour)
                pattern_feature = 0.5 + pattern_bonus * 0.5  # 0.5~1.0 ë²”ìœ„

            feature_vector = [rsi_feature, ma_feature, vol_feature, atr_feature, pattern_feature]
            features.append(feature_vector)

        return np.array(features)
#----------
    def train(self, df, force_retrain=False):
        """ì–‘ì ëª¨ë¸ í•™ìŠµ"""
        try:
            if not force_retrain:
                saved_model, saved_scaler = load_model(self.timeframe)
                if saved_model is not None and saved_scaler is not None:
                    # ì €ì¥ëœ ìŠ¤ì¼€ì¼ëŸ¬ì˜ íŠ¹ì§• ê°œìˆ˜ í™•ì¸
                    saved_feature_dim = None
                    if hasattr(saved_scaler, 'n_features_in_'):
                        saved_feature_dim = saved_scaler.n_features_in_
                    elif hasattr(saved_scaler, 'data_min_') and saved_scaler.data_min_ is not None:
                        saved_feature_dim = len(saved_scaler.data_min_)

                    # íŠ¹ì§• ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ì¬í•™ìŠµ
                    if saved_feature_dim is not None and saved_feature_dim == self.feature_dimension:
                        self.model = saved_model
                        self.scaler = saved_scaler
                        self.is_trained = True
                        logger.info(f"[SAVE] ì €ì¥ëœ {self.timeframe} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (íŠ¹ì§• ê°œìˆ˜: {saved_feature_dim})")
                        return
                    else:
                        logger.warning(
                            f"[WARN] ì €ì¥ëœ ìŠ¤ì¼€ì¼ëŸ¬ì˜ íŠ¹ì§• ê°œìˆ˜({saved_feature_dim})ì™€ í˜„ì¬ íŠ¹ì§• ê°œìˆ˜({self.feature_dimension})ê°€ ë‹¤ë¦…ë‹ˆë‹¤. ì¬í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.")

            logger.info(f"[QUANTUM] {self.timeframe} ì–‘ì ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ì¤‘...")
            X = self.prepare_quantum_features(df)
            y = (df['close'].shift(-1) > df['close']).astype(int).values

            min_length = min(len(X), len(y))
            X = X[:min_length]
            y = y[:min_length]

            if len(X) < 20:
                logger.warning(f"[WARN] {self.timeframe} ë°ì´í„° ë¶€ì¡± - ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")
                if len(X) > 10:
                    self.scaler.fit(X)
                    X_scaled = self.scaler.transform(X)
                    self.model = SVC()
                    self.model.fit(X_scaled, y)
                    self.is_trained = True
                return

            # ìŠ¤ì¼€ì¼ëŸ¬ ì¬í•™ìŠµ (íŠ¹ì§• ê°œìˆ˜ ì¼ê´€ì„± ìœ ì§€)
            self.scaler.fit(X)
            X_scaled = self.scaler.transform(X)

            split_idx = int(len(X_scaled) * 0.8)
            X_train, X_test = X_scaled[:split_idx], X_scaled[split_idx:]
            y_train, y_test = y[:split_idx], y[split_idx:]

            self.model = SVC()
            self.model.fit(X_train, y_train)

            train_score = self.model.score(X_train, y_train)
            test_score = self.model.score(X_test, y_test) if len(X_test) > 0 else 0

            logger.info(f"[OK] {self.timeframe} ëª¨ë¸ í•™ìŠµ ì™„ë£Œ - Train: {train_score:.3f}, Test: {test_score:.3f}")
            self.is_trained = True

            self.training_history.append({
                'timestamp': datetime.now().isoformat(),
                'train_score': train_score,
                'test_score': test_score,
                'data_size': len(X)
            })

            save_model(self.model, self.scaler, self.timeframe)

        except Exception as e:
            logger.error(f"[ERROR] {self.timeframe} ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ëª¨ë¸ë¡œ ëŒ€ì²´
            X = self.prepare_quantum_features(df)
            y = (df['close'].shift(-1) > df['close']).astype(int).values

            min_length = min(len(X), len(y))
            X = X[:min_length]
            y = y[:min_length]

            if len(X) > 10:
                self.scaler.fit(X)
                X_scaled = self.scaler.transform(X)
                self.model = SVC()
                self.model.fit(X_scaled, y)
                self.is_trained = True
                logger.info(f"[OK] {self.timeframe} ê¸°ë³¸ ë¶„ë¥˜ê¸°ë¡œ ëŒ€ì²´ í•™ìŠµ ì™„ë£Œ")
#---------------------
    def predict(self, df):
        """ì–‘ì ëª¨ë¸ ì˜ˆì¸¡"""
        if not self.is_trained or self.model is None:
            logger.warning(f"[WARN] {self.timeframe} ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•ŠìŒ - ê¸°ë³¸ ì˜ˆì¸¡ê°’ ë°˜í™˜")
            return 1

        try:
            X = self.prepare_quantum_features(df)
            if len(X) == 0:
                return 1

            latest_features = X[-1].reshape(1, -1)
            latest_features_scaled = self.scaler.transform(latest_features)
            prediction = self.model.predict(latest_features_scaled)[0]
            return prediction
        except Exception as e:
            logger.error(f"[ERROR] {self.timeframe} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return 1


# === ê±°ë˜ ê´€ë ¨ í•¨ìˆ˜ ===
def fetch_ohlcv(timeframe="15m", limit=200):
    """OHLCV ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        ohlcv = exchange.fetch_ohlcv(SYMBOL, timeframe=timeframe, limit=limit)
        if not ohlcv or len(ohlcv) < 10:
            logger.warning(f"[WARN] OHLCV ë°ì´í„° ë¶€ì¡± ({len(ohlcv)})")
            return None
        df = pd.DataFrame(ohlcv, columns=["ts", "open", "high", "low", "close", "volume"])
        df['ts'] = pd.to_datetime(df['ts'], unit="ms")
        return df
    except Exception as e:
        logger.error(f"[ERROR] OHLCV ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


def get_current_price():
    """í˜„ì¬ ê°€ê²© ì¡°íšŒ"""
    try:
        ticker = exchange.fetch_ticker(SYMBOL)
        return ticker['last']
    except Exception as e:
        logger.error(f"[ERROR] í˜„ì¬ ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


def set_leverage(leverage):
    """ë ˆë²„ë¦¬ì§€ ì„¤ì •"""
    try:
        logger.info(f"[LEVERAGE] ë ˆë²„ë¦¬ì§€ ì„¤ì • ì‹œë„: {leverage}x")

        # ë ˆë²„ë¦¬ì§€ ì„¤ì • íŒŒë¼ë¯¸í„°
        params = {
            'leverage': leverage,
            'marginMode': TRADING_MODE
        }

        # ë ˆë²„ë¦¬ì§€ ì„¤ì •
        result = exchange.set_leverage(leverage, SYMBOL, params)
        logger.info(f"[LEVERAGE] ë ˆë²„ë¦¬ì§€ ì„¤ì • ì™„ë£Œ: {leverage}x")
        return True
    except Exception as e:
        logger.error(f"[ERROR] ë ˆë²„ë¦¬ì§€ ì„¤ì • ì‹¤íŒ¨: {e}")
        return False


def moving_average_crossover(df, short_window=5, long_window=20):
    """ì´ë™í‰ê·  êµì°¨ ì‹ í˜¸"""
    try:
        if len(df) < long_window:
            return None
        short_ma = df['close'].rolling(window=short_window).mean()
        long_ma = df['close'].rolling(window=long_window).mean()
        if np.isnan(short_ma.iloc[-1]) or np.isnan(long_ma.iloc[-1]):
            return None
        if short_ma.iloc[-1] > long_ma.iloc[-1]:
            return 1
        else:
            return 0
    except Exception as e:
        logger.error(f"ì´ë™í‰ê·  ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def detect_market_regime(df):
    """ì‹œì¥ ìƒíƒœ ê°ì§€"""
    if df is None or len(df) < 200:
        return "UNKNOWN"

    try:
        df_with_indicators = add_technical_indicators(df)
        ma_short = df_with_indicators['ma20']
        ma_long = df_with_indicators['close'].rolling(200).mean()

        returns = df_with_indicators['return'].dropna()
        if len(returns) < 20:
            volatility = 0.0
        else:
            volatility = returns.tail(20).std() * np.sqrt(365 * 24)

        if len(ma_short) > 0 and len(ma_long) > 0 and not np.isnan(ma_short.iloc[-1]) and not np.isnan(
                ma_long.iloc[-1]):
            trend_strength = (ma_short.iloc[-1] - ma_long.iloc[-1]) / ma_long.iloc[-1]
        else:
            trend_strength = 0.0

        rsi = df_with_indicators['rsi'].iloc[-1] if 'rsi' in df_with_indicators.columns and len(
            df_with_indicators['rsi']) > 0 else 50

        if abs(trend_strength) > 0.02:
            if trend_strength > 0:
                if volatility > 0.03:
                    return "BULL_HIGH_VOL"
                else:
                    return "BULL_LOW_VOL"
            else:
                if volatility > 0.03:
                    return "BEAR_HIGH_VOL"
                else:
                    return "BEAR_LOW_VOL"
        else:
            if volatility > 0.025:
                return "SIDEWAYS_HIGH_VOL"
            else:
                return "SIDEWAYS_LOW_VOL"

    except Exception as e:
        logger.error(f"ì‹œì¥ Regime ê°ì§€ ì‹¤íŒ¨: {e}")
        return "UNKNOWN"


def get_trade_pattern(df):
    """ê±°ë˜ íŒ¨í„´ ì¶”ì¶œ"""
    if df is None or len(df) < 15:
        return []
    pattern = []
    try:
        closes = df['close'].iloc[-10:]
        for i in range(1, len(closes)):
            if closes.iloc[i] > closes.iloc[i - 1]:
                pattern.append(1)
            elif closes.iloc[i] < closes.iloc[i - 1]:
                pattern.append(-1)
            else:
                pattern.append(0)
    except Exception as e:
        logger.error(f"ê±°ë˜ íŒ¨í„´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        pattern = []
    return pattern


def get_account_and_position_status():
    """ê³„ì • ë° í¬ì§€ì…˜ ìƒíƒœ í™•ì¸"""
    try:
        # ê³„ì • ì”ê³  ì¡°íšŒ
        balance = exchange.fetch_balance()
        usdt_balance = balance.get('USDT', {})
        total_balance = usdt_balance.get('total', 0.0)
        free_balance = usdt_balance.get('free', 0.0)
        used_balance = usdt_balance.get('used', 0.0)

        if PERFORMANCE_DATA['initial_balance'] == 0 and total_balance > 0:
            PERFORMANCE_DATA['initial_balance'] = total_balance

        initial_balance = PERFORMANCE_DATA['initial_balance']
        total_pnl_percent = ((total_balance - initial_balance) / initial_balance) * 100 if initial_balance > 0 else 0

        balance_details = {
            'total': total_balance,
            'free': free_balance,
            'used': used_balance,
            'total_pnl_percent': total_pnl_percent,
            'initial_balance': initial_balance
        }

        # í¬ì§€ì…˜ ì •ë³´ ì¡°íšŒ
        positions = exchange.fetch_positions([SYMBOL])
        active_positions = []

        for pos in positions:
            if float(pos.get('contracts', 0)) != 0:
                entry_price = float(pos.get('entryPrice', 0))
                size = float(pos.get('contracts', 0))
                side = pos.get('side', '').lower()  # OKXëŠ” ì†Œë¬¸ì ì‚¬ìš©
                unrealized_pnl = float(pos.get('unrealizedPnl', 0))
                leverage = float(pos.get('leverage', 1))

                # í˜„ì¬ ê°€ê²©ìœ¼ë¡œ PNL% ê³„ì‚° (ë ˆë²„ë¦¬ì§€ ë°˜ì˜)
                current_price = get_current_price()
                if current_price and entry_price > 0:
                    if side == 'long':
                        pnl_percent = ((current_price - entry_price) / entry_price) * 100 * leverage
                    else:  # short
                        pnl_percent = ((entry_price - current_price) / entry_price) * 100 * leverage
                else:
                    pnl_percent = 0.0

                position_id = f"{pos.get('symbol')}_{side}_{entry_price}"

                active_positions.append({
                    "position_id": position_id,
                    "symbol": pos.get('symbol'),
                    "side": side,
                    "size": size,
                    "entry_price": entry_price,
                    "pnl": unrealized_pnl,
                    "floating_pnl_percent": pnl_percent,
                    "current_price": current_price,
                    "leverage": leverage,
                    "timestamp": datetime.now().isoformat()
                })

        return balance_details, active_positions

    except Exception as e:
        logger.error(f"[ERROR] ì”ê³ /í¬ì§€ì…˜ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None, []


def display_account_info(balance, positions, current_price):
    """ê³„ì • ì •ë³´ í‘œì‹œ"""
    try:
        print("\n" + "=" * 80)
        print("[CHART] REAL-TIME ACCOUNT STATUS")
        print("=" * 80)

        # ì”ê³  ì •ë³´
        if balance:
            print(f"[MONEY] USDT Balance: {balance['total']:.2f} USDT")
            print(f"        â”œâ”€ Available: {balance['free']:.2f} USDT")
            print(f"        â”œâ”€ In Use: {balance['used']:.2f} USDT")
            print(f"        â””â”€ Total PnL: {balance['total_pnl_percent']:+.2f}%")

        # í˜„ì¬ ê°€ê²©
        if current_price:
            print(f"[UP] Current BTC Price: {current_price:.2f} USDT")

        # í¬ì§€ì…˜ ì •ë³´
        if positions:
            print(f"[TARGET] Active Positions: {len(positions)}")
            for i, pos in enumerate(positions, 1):
                pnl_color = "[UP]" if pos['pnl'] > 0 else "[DOWN]"
                print(f"        {i}. {pos['side'].upper()} {pos['size']:.3f} contracts")
                print(f"             â”œâ”€ Entry: {pos['entry_price']:.2f} USDT")
                print(f"             â”œâ”€ Current: {pos['current_price']:.2f} USDT")
                print(f"             â”œâ”€ PnL: {pos['pnl']:+.3f} USDT {pnl_color}")
                print(f"             â”œâ”€ PnL%: {pos['floating_pnl_percent']:+.2f}% {pnl_color}")
                print(f"             â””â”€ Leverage: {pos['leverage']}x")
        else:
            print("[TARGET] Active Positions: None")

        print("=" * 80 + "\n")

    except Exception as e:
        logger.error(f"[ERROR] ê³„ì • ì •ë³´ í‘œì‹œ ì‹¤íŒ¨: {e}")


def generate_clordid():
    """ì£¼ë¬¸ ID ìƒì„±"""
    timestamp = str(int(time.time() * 1000))[-8:]
    random_str = ''.join(random.choices(string.ascii_uppercase + string.digits, k=8))
    return f"{timestamp}{random_str}"


def execute_order(params):
    """ì£¼ë¬¸ ì‹¤í–‰"""
    try:
        if 'params' not in params:
            params['params'] = {}
        params['params']['tdMode'] = TRADING_MODE

        return exchange.create_order(**params)
    except Exception as e:
        logger.error(f"[ERROR] ì£¼ë¬¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise e


def place_order(signal: int, amount: float) -> bool:
    """ì£¼ë¬¸ placement"""
    try:
        side = 'buy' if signal == 1 else 'sell'
        logger.info(f"[LAUNCH] ì‹ ê·œ ì£¼ë¬¸: {side.upper()} / {amount:.3f} ê³„ì•½ (ëª¨ë“œ: {TRADING_MODE}, ë ˆë²„ë¦¬ì§€: {LEVERAGE}x)")

        params = {
            "symbol": SYMBOL,
            "type": "market",
            "side": side,
            "amount": amount,
            "params": {
                "tdMode": TRADING_MODE,
            }
        }

        params["params"]["clOrdId"] = generate_clordid()

        result = execute_order(params)
        logger.info(f"[OK] ì£¼ë¬¸ ì„±ê³µ: {result['id']}")

        # ì£¼ë¬¸ ì„±ê³µ í›„ íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì´ˆê¸°í™”
        time.sleep(2)  # ì ì‹œ ëŒ€ê¸° í›„ í¬ì§€ì…˜ í™•ì¸
        balance, positions = get_account_and_position_status()
        if positions:
            position = positions[0]
            current_price = get_current_price()
            if current_price:
                initialize_trailing_stop(
                    position['position_id'],
                    position['entry_price'],
                    position['side'],
                    current_price
                )

        return True
    except Exception as e:
        logger.error(f"[ERROR] ì£¼ë¬¸ ì‹¤íŒ¨: {e}")
        return False


def close_position(position: Dict, amount: float, description: str) -> bool:
    """í¬ì§€ì…˜ ì²­ì‚°"""
    try:
        side = "sell" if position["side"] == "long" else "buy"
        logger.info(f"[LOCK] {description} ì‹¤í–‰: {position['side'].upper()} / {amount:.3f} ê³„ì•½")

        params = {
            "symbol": SYMBOL,
            "type": "market",
            "side": side,
            "amount": amount,
            "params": {
                "tdMode": TRADING_MODE,
            }
        }

        params["params"]["clOrdId"] = generate_clordid()

        result = execute_order(params)
        logger.info(f"[OK] ì²­ì‚° ì„±ê³µ: {result['id']}")

        # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì œê±°
        remove_trailing_stop(position['position_id'])

        pnl_usdt = position['pnl']
        pnl_percent = position['floating_pnl_percent']
        market_regime = detect_market_regime(fetch_ohlcv(timeframe=TIMEFRAME_15M, limit=100))
        hour_of_day = datetime.now().hour

        record_trade(position, pnl_usdt, pnl_percent, market_regime, hour_of_day)
        return True
    except Exception as e:
        logger.error(f"[ERROR] ì²­ì‚° ì‹¤íŒ¨: {e}")
        return False


def check_profit_loss_conditions(position):
    """ìˆ˜ìµ/ì†ì‹¤ ì¡°ê±´ ì²´í¬"""
    if not position:
        return False

    pnl_percent = position['floating_pnl_percent']

    if pnl_percent >= TAKE_PROFIT_PERCENT:
        logger.info(f"[TARGET] ìµì ˆ ì¡°ê±´ ë‹¬ì„±: {pnl_percent:.2f}% â‰¥ {TAKE_PROFIT_PERCENT}%")
        return close_position(position, position['size'], f"ìµì ˆ ({pnl_percent:.2f}%)")

    elif pnl_percent <= STOP_LOSS_PERCENT:
        logger.info(f"[WARN] ì†ì ˆ ì¡°ê±´ ë‹¬ì„±: {pnl_percent:.2f}% â‰¤ {STOP_LOSS_PERCENT}%")
        return close_position(position, position['size'], f"ì†ì ˆ ({pnl_percent:.2f}%)")

    return False


def check_trailing_stop_conditions():
    """íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì¡°ê±´ ì²´í¬"""
    try:
        current_price = get_current_price()
        if not current_price:
            return False

        positions_to_close = check_all_trailing_stops(current_price)

        if positions_to_close:
            balance, positions = get_account_and_position_status()
            for position_id in positions_to_close:
                # í•´ë‹¹ í¬ì§€ì…˜ ì°¾ê¸°
                position_to_close = None
                for pos in positions:
                    if pos['position_id'] == position_id:
                        position_to_close = pos
                        break

                if position_to_close:
                    logger.info(f"[TRAILING] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì²­ì‚° ì‹¤í–‰: {position_id}")
                    close_position(position_to_close, position_to_close['size'],
                                   f"íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì²­ì‚° ({TRAILING_STOP_PERCENT}%)")
                    return True

        return False
    except Exception as e:
        logger.error(f"[ERROR] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì¡°ê±´ ì²´í¬ ì‹¤íŒ¨: {e}")
        return False


# === ìˆ˜ì •ëœ ê±°ë˜ ê¸°ë¡ í•¨ìˆ˜ ===
def record_trade(position_data, pnl_usdt, pnl_percent, market_regime, hour_of_day, signal_accuracy=None,
                 trade_pattern=None):
    """ê±°ë˜ ê¸°ë¡ ì €ì¥ (íŒ¨í„´ í•™ìŠµ í¬í•¨)"""
    trade_record = {
        'timestamp': datetime.now().isoformat(),
        'symbol': position_data.get('symbol', SYMBOL),
        'side': position_data.get('side', 'UNKNOWN'),
        'pnl_usdt': pnl_usdt,
        'pnl_percent': pnl_percent,
        'market_regime': market_regime,
        'hour_of_day': hour_of_day,
        'signal_accuracy': signal_accuracy,
        'trade_pattern': trade_pattern,
        'duration_minutes': position_data.get('duration_minutes', 0)
    }

    # ê¸°ì¡´ ì„±ê³¼ ë°ì´í„° ì—…ë°ì´íŠ¸
    PERFORMANCE_DATA['total_trades'] += 1
    PERFORMANCE_DATA['total_pnl'] += pnl_usdt

    if pnl_usdt > 0:
        PERFORMANCE_DATA['winning_trades'] += 1

    PERFORMANCE_DATA['recent_trades'].append(trade_record)

    # íŒ¨í„´ í•™ìŠµ ì—…ë°ì´íŠ¸
    update_pattern_learning(trade_record)

    # ê¸°ì¡´ ì„±ê³¼ ë¶„ì„ ë°ì´í„° ì—…ë°ì´íŠ¸
    if trade_pattern:
        pattern_key = str(trade_pattern)
        if pattern_key not in PERFORMANCE_DATA['similar_trade_patterns']:
            PERFORMANCE_DATA['similar_trade_patterns'][pattern_key] = {
                'count': 0,
                'total_pnl': 0.0,
                'winning_trades': 0
            }

        PERFORMANCE_DATA['similar_trade_patterns'][pattern_key]['count'] += 1
        PERFORMANCE_DATA['similar_trade_patterns'][pattern_key]['total_pnl'] += pnl_usdt
        if pnl_usdt > 0:
            PERFORMANCE_DATA['similar_trade_patterns'][pattern_key]['winning_trades'] += 1

    if signal_accuracy is not None:
        PERFORMANCE_DATA['signal_accuracy_history'].append(signal_accuracy)

    regime = market_regime
    if regime not in PERFORMANCE_DATA['market_regime_performance']:
        PERFORMANCE_DATA['market_regime_performance'][regime] = {'trades': 0, 'total_pnl': 0.0, 'wins': 0}

    PERFORMANCE_DATA['market_regime_performance'][regime]['trades'] += 1
    PERFORMANCE_DATA['market_regime_performance'][regime]['total_pnl'] += pnl_usdt
    if pnl_usdt > 0:
        PERFORMANCE_DATA['market_regime_performance'][regime]['wins'] += 1

    hour_key = f"hour_{hour_of_day}"
    if hour_key not in PERFORMANCE_DATA['time_based_performance']:
        PERFORMANCE_DATA['time_based_performance'][hour_key] = {'trades': 0, 'total_pnl': 0.0, 'wins': 0}

    PERFORMANCE_DATA['time_based_performance'][hour_key]['trades'] += 1
    PERFORMANCE_DATA['time_based_performance'][hour_key]['total_pnl'] += pnl_usdt
    if pnl_usdt > 0:
        PERFORMANCE_DATA['time_based_performance'][hour_key]['wins'] += 1

    log_performance(f"{pnl_usdt},{pnl_percent},{regime},{hour_of_day}")
    save_trade_history()


def find_similar_profitable_trade(current_pattern):
    """ìœ ì‚¬í•œ ìˆ˜ìµì„± ê±°ë˜ íŒ¨í„´ ì°¾ê¸°"""
    if not current_pattern or not PERFORMANCE_DATA['similar_trade_patterns']:
        return None

    current_key = str(current_pattern)
    similar_patterns = {}

    for pattern_key, stats in PERFORMANCE_DATA['similar_trade_patterns'].items():
        if stats['count'] >= 2:
            win_rate = stats['winning_trades'] / stats['count']
            avg_pnl = stats['total_pnl'] / stats['count']

            if win_rate > 0.6 or avg_pnl > 0:
                similar_patterns[pattern_key] = {
                    'win_rate': win_rate,
                    'avg_pnl': avg_pnl,
                    'count': stats['count']
                }

    if similar_patterns:
        best_pattern = max(similar_patterns.items(),
                           key=lambda x: (x[1]['win_rate'], x[1]['avg_pnl']))
        return best_pattern[0], best_pattern[1]

    return None


def performance_analysis():
    """ì„±ê³¼ ë¶„ì„"""
    if len(PERFORMANCE_DATA['recent_trades']) < 5:
        return

    recent_trades = list(PERFORMANCE_DATA['recent_trades'])
    win_rate = len([t for t in recent_trades if t['pnl_usdt'] > 0]) / len(recent_trades)
    avg_win = np.mean([t['pnl_usdt'] for t in recent_trades if t['pnl_usdt'] > 0]) if any(
        t['pnl_usdt'] > 0 for t in recent_trades) else 0
    avg_loss = np.mean([t['pnl_usdt'] for t in recent_trades if t['pnl_usdt'] < 0]) if any(
        t['pnl_usdt'] < 0 for t in recent_trades) else 0

    logger.info(f"[CHART] ì„±ê³¼ ë¶„ì„ - ìŠ¹ë¥ : {win_rate:.2%}, í‰ê·  ì´ìµ: {avg_win:.4f}, í‰ê·  ì†ì‹¤: {avg_loss:.4f}")

    if PERFORMANCE_DATA['signal_accuracy_history']:
        accuracy_rate = sum(PERFORMANCE_DATA['signal_accuracy_history']) / len(
            PERFORMANCE_DATA['signal_accuracy_history'])
        logger.info(f"[TARGET] ì‹ í˜¸ ì •í™•ë„: {accuracy_rate:.2%}")

        global INTERVAL_WAITING
        if accuracy_rate < 0.5:
            INTERVAL_WAITING = 600
            logger.info("[WARN] ì‹ í˜¸ ì •í™•ë„ ë‚®ìŒ - ëŒ€ê¸° ì‹œê°„ ì¦ê°€")
        else:
            INTERVAL_WAITING = 300


def get_optimal_trading_time():
    """ìµœì  ê±°ë˜ ì‹œê°„ ë¶„ì„"""
    if not PERFORMANCE_DATA['time_based_performance']:
        return None

    best_hour = None
    best_performance = -float('inf')

    for hour_key, stats in PERFORMANCE_DATA['time_based_performance'].items():
        if stats['trades'] >= 3:
            avg_pnl = stats['total_pnl'] / stats['trades']
            if avg_pnl > best_performance:
                best_performance = avg_pnl
                best_hour = int(hour_key.split('_')[1])

    return best_hour


# === ë©”ì¸ í•¨ìˆ˜ ===
def main():
    global PERFORMANCE_DATA, LEVERAGE, TAKE_PROFIT_PERCENT, STOP_LOSS_PERCENT

    # ëª…ë ¹ì¤„ ì¸ì ì²˜ë¦¬
    parser = argparse.ArgumentParser(description='ì–‘ì íŠ¸ë ˆì´ë”© ë´‡')
    parser.add_argument('--mode', type=str, default='trade', choices=['trade', 'backtest', 'train'],
                        help='ì‹¤í–‰ ëª¨ë“œ: trade(ì‹¤ê±°ë˜), backtest(ë°±í…ŒìŠ¤íŠ¸), train(í•™ìŠµë§Œ)')
    parser.add_argument('--retrain', action='store_true', help='ëª¨ë¸ ì¬í•™ìŠµ')
    parser.add_argument('--analyze-patterns', action='store_true', help='íŒ¨í„´ ë¶„ì„ë§Œ ì‹¤í–‰')
    parser.add_argument('--leverage', type=int, default=100, help='ë ˆë²„ë¦¬ì§€ ì„¤ì • (ê¸°ë³¸ê°’: 100)')
    args = parser.parse_args()

    # ë ˆë²„ë¦¬ì§€ ì„¤ì • ì ìš©
    LEVERAGE = args.leverage
    TAKE_PROFIT_PERCENT = 3000.0 / LEVERAGE
    STOP_LOSS_PERCENT = -5000.0 / LEVERAGE

    if args.analyze_patterns:
        load_pattern_learning()
        analyze_pattern_performance()
        sys.exit(0)

    if args.mode == 'train' or args.retrain:
        logger.info("[TARGET] í•™ìŠµ ëª¨ë“œ ì‹¤í–‰")
        df_15m = fetch_ohlcv(timeframe=TIMEFRAME_15M, limit=1000)
        df_4h = fetch_ohlcv(timeframe=TIMEFRAME_4H, limit=1000)
        if df_15m is not None and df_4h is not None:
            quantum_model_15m = QuantumTradingModel(timeframe="15m")
            quantum_model_4h = QuantumTradingModel(timeframe="4h")
            quantum_model_15m.train(df_15m, force_retrain=True)
            quantum_model_4h.train(df_4h, force_retrain=True)
        sys.exit(0)

    # ë©”ì¸ íŠ¸ë ˆì´ë”© ë£¨í”„
    PERFORMANCE_DATA = load_trade_history()
    load_trailing_stops()
    load_pattern_learning()  # íŒ¨í„´ í•™ìŠµ ë°ì´í„° ë¡œë“œ

    quantum_model_15m = QuantumTradingModel(timeframe="15m")
    quantum_model_4h = QuantumTradingModel(timeframe="4h")

    error_count, max_errors = 0, 5
    time_to_wait = 0
    waiting_mode = False

    logger.info("[LAUNCH] Ubuntu OKX íŠ¸ë ˆì´ë”© ë´‡ ì‹œì‘ (íŒ¨í„´ í•™ìŠµ í™œì„±í™”)")
    logger.info(f"[CHART] ì´ì „ ê±°ë˜ ê¸°ë¡: {PERFORMANCE_DATA['total_trades']}íšŒ ê±°ë˜")
    logger.info(f"[LEARN] í•™ìŠµëœ íŒ¨í„´: {len(PATTERN_LEARNING_DATA['profitable_patterns'])}ê°œ ìˆ˜ìµì„± íŒ¨í„´")
    logger.info(f"[LEARN] íŒ¨í„´ ê°€ì¤‘ì¹˜: {len(PATTERN_LEARNING_DATA['pattern_weights'])}ê°œ íŒ¨í„´ì— ê°€ì¤‘ì¹˜ ì ìš©")
    logger.info(f"[LEVERAGE] ì„¤ì • ë ˆë²„ë¦¬ì§€: {LEVERAGE}x")
    logger.info(f"[LEVERAGE] ì¡°ì •ëœ ìµì ˆ: {TAKE_PROFIT_PERCENT:.2f}%")
    logger.info(f"[LEVERAGE] ì¡°ì •ëœ ì†ì ˆ: {STOP_LOSS_PERCENT:.2f}%")
    logger.info(f"[TOOL] ê±°ë˜ ëª¨ë“œ: {TRADING_MODE}")
    logger.info(f"[TRAILING] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘: {TRAILING_STOP_PERCENT}%")
    logger.info(f"[FOLDER] ë°ì´í„° ë””ë ‰í† ë¦¬: {DATA_DIR}")
    logger.info(f"[PC] í”Œë«í¼: {'Ubuntu/Linux' if IS_LINUX else 'Windows'}")
    logger.info(f"[ROBOT] ë¨¸ì‹ ëŸ¬ë‹: {'scikit-learn ì‚¬ìš©' if SKLEARN_AVAILABLE else 'ë‹¨ìˆœ êµ¬í˜„ì²´ ì‚¬ìš©'}")
    logger.info(f"[TIME] íƒ€ì„í”„ë ˆì„: 15ë¶„ë´‰ & 4ì‹œê°„ë´‰")
    logger.info(f"[TARGET] ì‹ í˜¸ ì¼ì¹˜ ì„ê³„ê°’: {SIGNAL_MATCH_THRESHOLD:.0%}")

    # API ì¸ì¦ ìƒíƒœ í‘œì‹œ
    if API_KEY and API_SECRET and API_PASSPHRASE:
        logger.info("[OK] API ì¸ì¦: ì‹¤ê±°ë˜ ëª¨ë“œ")
        # ë ˆë²„ë¦¬ì§€ ì„¤ì •
        if not set_leverage(LEVERAGE):
            logger.warning("[WARN] ë ˆë²„ë¦¬ì§€ ì„¤ì • ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
    else:
        logger.info("[WARN] API ì¸ì¦: ìƒŒë“œë°•ìŠ¤ ëª¨ë“œ (ê³µê°œ ë°ì´í„°ë§Œ ì¡°íšŒ ê°€ëŠ¥)")

    # ì´ˆê¸° íŒ¨í„´ ë¶„ì„ ì‹¤í–‰
    analyze_pattern_performance()

    while True:
        try:
            time.sleep(time_to_wait)
            start_time = time.time()

            # ì£¼ê¸°ì  ëª¨ë¸ ì¬í•™ìŠµ (6ì‹œê°„ë§ˆë‹¤)
            current_hour = datetime.now().hour
            if current_hour % 6 == 0:  # 6ì‹œê°„ë§ˆë‹¤ ì¬í•™ìŠµ
                retrain_models_with_patterns()
                analyze_pattern_performance()

            # í˜„ì¬ ê°€ê²© ì¡°íšŒ (íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì²´í¬ìš©)
            current_price = get_current_price()

            # ê³„ì • ì •ë³´ ì¡°íšŒ ë° í‘œì‹œ
            balance, positions = get_account_and_position_status()
            display_account_info(balance, positions, current_price)

            if current_price:
                # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì¡°ê±´ ì²´í¬
                trailing_stop_triggered = check_trailing_stop_conditions()
                if trailing_stop_triggered:
                    logger.info("[TRAILING] íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì²­ì‚° ì‹¤í–‰ë¨")
                    time.sleep(5)  # ì²­ì‚° í›„ ì ì‹œ ëŒ€ê¸°

            # 15ë¶„ë´‰ê³¼ 4ì‹œê°„ë´‰ ë°ì´í„° ì¡°íšŒ
            df_15m = fetch_ohlcv(timeframe=TIMEFRAME_15M, limit=CANDLE_LIMIT)
            df_4h = fetch_ohlcv(timeframe=TIMEFRAME_4H, limit=CANDLE_LIMIT)

            if df_15m is None or df_4h is None:
                error_count += 1
                time_to_wait = INTERVAL_NORMAL
                if error_count >= max_errors:
                    break
                continue

            # ëª¨ë¸ í•™ìŠµ (í•„ìš”ì‹œ)
            if not quantum_model_15m.is_trained:
                quantum_model_15m.train(df_15m)
            if not quantum_model_4h.is_trained:
                quantum_model_4h.train(df_4h)

            # ì–‘ì ì˜ˆì¸¡
            quantum_signal_15m = quantum_model_15m.predict(df_15m)
            quantum_signal_4h = quantum_model_4h.predict(df_4h)

            quantum_text_15m = 'ìƒìŠ¹(BUY)' if quantum_signal_15m == 1 else 'í•˜ë½(SELL)'
            quantum_text_4h = 'ìƒìŠ¹(BUY)' if quantum_signal_4h == 1 else 'í•˜ë½(SELL)'

            logger.info(f"[QUANTUM] 15M ì–‘ì ì˜ˆì¸¡: {quantum_text_15m}")
            logger.info(f"[QUANTUM] 4H ì–‘ì ì˜ˆì¸¡: {quantum_text_4h}")

            # ê¸°ì¡´ ê¸°ìˆ ì  ë¶„ì„ ì‹ í˜¸
            signal_15m = moving_average_crossover(df_15m)
            signal_4h = moving_average_crossover(df_4h)

            if signal_15m is None or signal_4h is None:
                logger.warning("[ERROR] ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨ - ê¸°ë³¸ ì „ëµ ì‚¬ìš©")
                signal_15m = 1
                signal_4h = 1

            # ì‹ í˜¸ ì¼ì¹˜ìœ¨ ê³„ì‚°
            signals_15m_match = (signal_15m == quantum_signal_15m)
            signals_4h_match = (signal_4h == quantum_signal_4h)
            total_match_rate = (int(signals_15m_match) + int(signals_4h_match)) / 2.0

            logger.info(f"[RADAR] 15M ì‹ í˜¸ ì¼ì¹˜: {'[OK] ì¼ì¹˜' if signals_15m_match else '[ERROR] ë¶ˆì¼ì¹˜'}")
            logger.info(f"[RADAR] 4H ì‹ í˜¸ ì¼ì¹˜: {'[OK] ì¼ì¹˜' if signals_4h_match else '[ERROR] ë¶ˆì¼ì¹˜'}")
            logger.info(f"[TARGET] ì „ì²´ ì‹ í˜¸ ì¼ì¹˜ìœ¨: {total_match_rate:.1%}")

            # ì‹œì¥ ìƒíƒœ ë¶„ì„
            market_regime = detect_market_regime(df_15m)
            logger.info(f"[TARGET] í˜„ì¬ ì‹œì¥ Regime: {market_regime}")

            current_pattern = get_trade_pattern(df_15m)
            similar_profitable_trade = find_similar_profitable_trade(current_pattern)

            if similar_profitable_trade:
                logger.info(f"[DICE] ìœ ì‚¬í•œ ìˆ˜ìµì„± íŒ¨í„´ ë°œê²¬: ìŠ¹ë¥  {similar_profitable_trade[1]['win_rate']:.1%}")

            performance_analysis()

            active_position = positions[0] if positions else None
            total_pnl_percent = balance.get('total_pnl_percent', 0) if balance else 0

            if active_position:
                logger.info(
                    f"[PACKAGE] í¬ì§€ì…˜ ê°ì§€: {active_position['side']}, PNL: {active_position['pnl']:.3f} USDT ({active_position['floating_pnl_percent']:.2f}%)")

                # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ì´ ì—†ëŠ” í¬ì§€ì…˜ì— ëŒ€í•´ ì´ˆê¸°í™”
                if active_position['position_id'] not in TRAILING_STOPS and current_price:
                    initialize_trailing_stop(
                        active_position['position_id'],
                        active_position['entry_price'],
                        active_position['side'],
                        current_price
                    )

                if total_pnl_percent <= EMERGENCY_LIQUIDATION_THRESHOLD:
                    logger.info(f"[FIRE] ê¸´ê¸‰ ì „ì²´ ì²­ì‚°! ì „ì²´ ìë³¸ ì†ì‹¤: {total_pnl_percent:.2f}%")
                    close_position(active_position, active_position['size'], "ê¸´ê¸‰ ì „ì²´ ì²­ì‚°")

                elif check_profit_loss_conditions(active_position):
                    logger.info("[SYNC] í¬ì§€ì…˜ ë³€ê²½ í›„ ìƒíƒœ ì—…ë°ì´íŠ¸ ì¤‘...")
                    time.sleep(3)
                    balance, positions = get_account_and_position_status()
                else:
                    logger.info("[OK] í˜„ì¬ í¬ì§€ì…˜ ìœ ì§€ ì¤‘")

            else:
                logger.info("[NEW] ì‹ ê·œ í¬ì§€ì…˜ ì§„ì… ê²€í†  ì¤‘...")

                # ì‹ í˜¸ ì¼ì¹˜ìœ¨ì´ ì„ê³„ê°’ ì´ìƒì¼ ë•Œë§Œ ë§¤ìˆ˜
                should_enter = (total_match_rate >= SIGNAL_MATCH_THRESHOLD)

                if should_enter:
                    logger.info(f"[OK] ì‹ í˜¸ ì¼ì¹˜ìœ¨ {total_match_rate:.1%} â‰¥ {SIGNAL_MATCH_THRESHOLD:.0%} - ì§„ì… ì¡°ê±´ ì¶©ì¡±")

                    # ìµœì¢… ì‹ í˜¸ ê²°ì • (ì–‘ì ì˜ˆì¸¡ ìš°ì„ )
                    final_signal = 1 if (quantum_signal_15m + quantum_signal_4h) >= 1 else 0
                    final_signal_text = 'ìƒìŠ¹(BUY)' if final_signal == 1 else 'í•˜ë½(SELL)'

                    best_hour = get_optimal_trading_time()
                    current_hour = datetime.now().hour
                    if best_hour is not None:
                        time_match = (current_hour == best_hour)
                        time_info = f" ({best_hour}ì‹œ - {'[OK] ìµœì ì‹œê°„' if time_match else '[WARN] ì¼ë°˜ì‹œê°„'})"
                    else:
                        time_info = ""

                    pattern_info = ""
                    if similar_profitable_trade:
                        pattern_info = f" [ìœ ì‚¬íŒ¨í„´ ìŠ¹ë¥ : {similar_profitable_trade[1]['win_rate']:.1%}]"

                    logger.info(f"[TARGET] ì§„ì… ê²°ì •: {final_signal_text}{time_info}{pattern_info}")

                    if place_order(final_signal, CONTRACT_AMOUNT):
                        logger.info("[SYNC] ì‹ ê·œ ì£¼ë¬¸ í›„ ìƒíƒœ ì—…ë°ì´íŠ¸ ì¤‘...")
                        time.sleep(3)
                        balance, positions = get_account_and_position_status()

                        # ì‹ í˜¸ ì •í™•ë„ ê¸°ë¡
                        signal_accuracy = (final_signal == 1 and df_15m['close'].iloc[-1] < df_15m['close'].iloc[-2]) or \
                                          (final_signal == 0 and df_15m['close'].iloc[-1] > df_15m['close'].iloc[-2])
                        PERFORMANCE_DATA['signal_accuracy_history'].append(signal_accuracy)
                else:
                    logger.info(
                        f"[PAUSE] ì‹ í˜¸ ë¶ˆì¼ì¹˜ ({total_match_rate:.1%} < {SIGNAL_MATCH_THRESHOLD:.0%}) - {INTERVAL_WAITING}ì´ˆ ëŒ€ê¸°")
                    waiting_mode = True

            if waiting_mode:
                monitoring_interval = INTERVAL_WAITING
                waiting_mode = False
            else:
                monitoring_interval = INTERVAL_ACTIVE if positions else INTERVAL_NORMAL

            error_count = 0
            elapsed_time = time.time() - start_time
            time_to_wait = max(0, monitoring_interval - elapsed_time)

            logger.info(f"[CLOCK] ë‹¤ìŒ ì‹¤í–‰ê¹Œì§€ {int(time_to_wait)}ì´ˆ ëŒ€ê¸°")

        except KeyboardInterrupt:
            logger.info("\n[STOP] ì‚¬ìš©ìì— ì˜í•´ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
            save_trade_history()
            save_trailing_stops()
            save_pattern_learning()  # íŒ¨í„´ í•™ìŠµ ë°ì´í„° ì €ì¥
            break
        except Exception as e:
            logger.error(f"[FIRE] ë©”ì¸ ë£¨í”„ ì˜¤ë¥˜: {e}")
            traceback.print_exc()
            error_count += 1
            if error_count >= max_errors:
                save_trade_history()
                save_trailing_stops()
                save_pattern_learning()  # íŒ¨í„´ í•™ìŠµ ë°ì´í„° ì €ì¥
                break
            time_to_wait = INTERVAL_NORMAL


if __name__ == "__main__":
    main()